---
type: knowledge
tags:
  - ai
---
# Función de activación:
Si en la neurona lo que hacíamos era calcular como valor de salida una suma ponderada de nuestras entradas, lo que queremos hacer ahora es pasar nuestro valor de salida por nuestra función de activación, lo que hará nuestra función de activación es distorsionar nuestro valor de salida añadiéndoles deformaciones no lineales. 

Puesto que si el resultado es una línea la red colapsaría dando como resultado una sola neurona al sumar varias líneas se tiene como resultado una única línea.

Las deformaciones dependen del tipo de función de activación.

## Tipos de función de activación
- [ ] #TODO  2023-11-13 

### Función escalonada
![[Pasted image 20231113212221.png]]

### Función sigmoide
![[Pasted image 20231113212328.png]]

### Función tangente hiperbólica 
![[Pasted image 20231113212446.png]]

### Función RELU unidad rectificada lineal
![[Pasted image 20231113212535.png]]



